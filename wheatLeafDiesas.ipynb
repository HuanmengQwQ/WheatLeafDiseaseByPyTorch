{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ws7Zb5gRzSn5",
        "outputId": "ac7f8b97-26ce-440b-d64f-a7e6acfc47f3"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIfYYHb5-_PM",
        "outputId": "69b71cbd-b1fb-4f7b-80e5-8abae91f2bcd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "path = \"/content\"\n",
        "os.chdir(path)\n",
        "\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhlEKVZc-2lt",
        "outputId": "a711961f-45be-4ab7-f4a4-f6c7fccd8b23"
      },
      "outputs": [],
      "source": [
        "!mkdir data\n",
        "# 复制测试集\n",
        "%cp -av /content/drive/MyDrive/PytorchTest/data/after.rar /content/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tzb-Ia3jQwfq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "path = \"/content/data\"\n",
        "os.chdir(path)\n",
        "!mkdir wheat-leaf-disease"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XC73qbHcAjeW",
        "outputId": "19b8d13c-a8a1-4377-a97a-fc4b6427062f"
      },
      "outputs": [],
      "source": [
        "# 解压\n",
        "!pip install pyunpack\n",
        "!pip install patool\n",
        "from pyunpack import Archive\n",
        "Archive('/content/data/after.rar').extractall('/content/data/wheat-leaf-disease')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9TqbGNtBhx0",
        "outputId": "1cb4996d-6964-4c71-87a2-741ac0b94586"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "path = \"/content\"\n",
        "os.chdir(path)\n",
        "\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyuOZUvtejoD"
      },
      "source": [
        "**导包**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "n8kZ97Vkeh-t"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import StepLR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5IzD6mjfwjn"
      },
      "source": [
        "**制作数据集**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 795
        },
        "id": "AtvgiVJ1f0o6",
        "outputId": "0794c7f0-1bf7-4164-b8e8-e202af67bdf5"
      },
      "outputs": [],
      "source": [
        "class_labels = ('Brown_rust', 'Healthy', 'Septoria', 'Yellow_rust')\n",
        "\n",
        "\n",
        "# 定义数据转换\n",
        "transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "\n",
        "# 生成索引\n",
        "def make_txt(root, file_name, label):\n",
        "    global f\n",
        "    path = os.path.join(root, file_name)\n",
        "\n",
        "    data = os.listdir(path)\n",
        "    if 'train' in root:\n",
        "        f = open(root + '/' + 'train_data.txt', 'a')\n",
        "\n",
        "    if 'val' in root:\n",
        "        f = open(root + '/' + 'val_data.txt', 'a')\n",
        "\n",
        "    for line in data:\n",
        "        f.write(line + ' ' + str(label) + ' ' + file_name + '\\n')\n",
        "    f.close()\n",
        "\n",
        "\n",
        "train_path = r'./data/wheat-leaf-disease/after/train'\n",
        "val_path = r'./data/wheat-leaf-disease/after/val'\n",
        "for index, value in enumerate(class_labels):\n",
        "    make_txt(train_path, file_name=value, label=index)\n",
        "    make_txt(val_path, file_name=value, label=index)\n",
        "\n",
        "\n",
        "# 读取训练集索引构成DataSet\n",
        "class WheatLeafBaseDataset(Dataset):\n",
        "    def __init__(self, img_path, split, transform=None):\n",
        "        super(WheatLeafBaseDataset, self).__init__()\n",
        "        self.root = img_path\n",
        "        self.split = split\n",
        "        self.txt_root = os.path.join(self.root, self.split, f'{self.split}_data.txt')\n",
        "        f = open(self.txt_root, 'r')\n",
        "        data = f.readlines()\n",
        "        imgs = []\n",
        "        labels = []\n",
        "        for line in data:\n",
        "            line = line.rstrip()\n",
        "            word = line.split()\n",
        "            imgs.append(os.path.join(self.root, self.split, word[2], word[0]))\n",
        "            labels.append(word[1])\n",
        "        self.img = imgs\n",
        "        self.label = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.label)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        img = self.img[item]\n",
        "        label = self.label[item]\n",
        "        img = Image.open(img).convert('RGB')\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        label = np.array(label).astype(np.int64)\n",
        "        label = torch.from_numpy(label)\n",
        "        return img, label\n",
        "\n",
        "\n",
        "class WheatLeafTrainDataset(WheatLeafBaseDataset):\n",
        "    def __init__(self, img_path, transform=None):\n",
        "        super(WheatLeafTrainDataset, self).__init__(img_path, 'train', transform)\n",
        "\n",
        "\n",
        "class WheatLeafValDataset(WheatLeafBaseDataset):\n",
        "    def __init__(self, img_path, transform=None):\n",
        "        super(WheatLeafValDataset, self).__init__(img_path, 'val', transform)\n",
        "\n",
        "\n",
        "path = r'./data/wheat-leaf-disease/after'\n",
        "\n",
        "train_dataset = WheatLeafTrainDataset(path, transform=transforms)\n",
        "val_dataset = WheatLeafValDataset(path, transform=transforms)\n",
        "\n",
        "train_data_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "val_data_loader = DataLoader(dataset=val_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "def ShowImage(data_loader):\n",
        "    for i, data in enumerate(data_loader):\n",
        "        images, labels = data\n",
        "\n",
        "        # 打印数据集中的图片\n",
        "        img = torchvision.utils.make_grid(images).numpy()\n",
        "        plt.imshow(np.transpose(img, (1, 2, 0)))\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "        break\n",
        "\n",
        "\n",
        "ShowImage(train_data_loader)\n",
        "ShowImage(val_data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwBh6_9hxvlH",
        "outputId": "c0d0515a-9014-4aa3-b40d-6788a4181c0f"
      },
      "outputs": [],
      "source": [
        "# 计算均值和标准差\n",
        "mean = torch.zeros(3)\n",
        "std = torch.zeros(3)\n",
        "\n",
        "for inputs, _ in train_data_loader:\n",
        "    mean += inputs.mean(dim=[0, 2, 3], keepdim=True).squeeze()\n",
        "    std += inputs.std(dim=[0, 2, 3], keepdim=True).squeeze()\n",
        "mean /= len(train_dataset)\n",
        "std /= len(train_dataset)\n",
        "\n",
        "print(f'Mean: {mean.tolist()}')\n",
        "print(f'Std: {std.tolist()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onz8uif2S_JZ",
        "outputId": "4b7b44c3-8b3e-48f8-ba65-b21fa814f4ba"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "# 数据预处理\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),  # 随机大小裁剪和缩放\n",
        "    transforms.RandomHorizontalFlip(),  # 随机水平翻转\n",
        "    transforms.ToTensor(),  # 转换为张量\n",
        "    transforms.Normalize(mean, std)  # 标准化\n",
        "])\n",
        "\n",
        "\n",
        "# 创建模型实例和定义损失函数、优化器\n",
        "model = models.vgg16(pretrained=True)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "model.classifier[6] = nn.Linear(4096,4)\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "def evaluate_accuracy(data_iter, net, device=None):\n",
        "    if device is None and isinstance(net, torch.nn.Module):\n",
        "        device = next(net.parameters()).device\n",
        "    acc_sum, n = 0.0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in data_iter:\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            net.eval()\n",
        "            acc_sum += (net(X).argmax(dim=1) == y).float().sum().cpu().item()\n",
        "            net.train()\n",
        "            n += y.shape[0]\n",
        "    return acc_sum / n\n",
        "\n",
        "\n",
        "def train(net, train_iter, test_iter, optimizer, device, num_epochs):\n",
        "    sum_time = 0.0\n",
        "\n",
        "    net = net.to(device)\n",
        "    print(\"training on\", device)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    for epoch in range(num_epochs):\n",
        "        train_l_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time()\n",
        "        for X, y in train_iter:\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            y_hat = net(X)\n",
        "            l = loss_fn(y_hat, y)\n",
        "            optimizer.zero_grad()\n",
        "            l.backward()\n",
        "            optimizer.step()\n",
        "            train_l_sum += l.cpu().item()\n",
        "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n",
        "            n += y.shape[0]\n",
        "            batch_count += 1\n",
        "\n",
        "        test_acc = evaluate_accuracy(test_iter, net)\n",
        "\n",
        "        print('epoch %d, loss %.4f, train acc %.3f%%, test acc %.3f%%, time %.1f sec'\n",
        "              % (epoch + 1, train_l_sum / batch_count, (train_acc_sum / n) * 100, test_acc * 100, time.time() - start))\n",
        "        loss_list.append((train_l_sum / batch_count))\n",
        "        acc_list.append(test_acc)\n",
        "        sum_time += (time.time() - start)\n",
        "        torch.save(net.state_dict(), f'/content/drive/MyDrive/PytorchTest/VGG16-wheatleafdiesas_RetrainingModel.pth')\n",
        "        # 降低梯度\n",
        "        scheduler.step(test_acc)\n",
        "\n",
        "        # 保存 loss_list 到文件\n",
        "    with open('/content/drive/MyDrive/PytorchTest/Loss_and_acc_result/CNN_loss.txt', 'w') as file:\n",
        "        for loss in loss_list:\n",
        "            file.write(str(loss) + '\\n')\n",
        "\n",
        "        # 保存 acc_list 到文件\n",
        "    with open('/content/drive/MyDrive/PytorchTest/Loss_and_acc_result/CNN_accuracy.txt', 'w') as file:\n",
        "        for acc in acc_list:\n",
        "            file.write(str(acc) + '\\n')\n",
        "    with open('/content/drive/MyDrive/PytorchTest/Loss_and_acc_result/CNN_times.txt', 'w') as file:\n",
        "        file.write(str(sum_time))\n",
        "\n",
        "\n",
        "lr, num_epochs = 0.001, 30\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True, min_lr=0.00000000001)\n",
        "train(model, train_data_loader, val_data_loader, optimizer, device, num_epochs)\n",
        "\n",
        "print('Training and testing completed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "SHtARkXeqWJz",
        "outputId": "09bd6142-1105-4090-bd39-db99a615820f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(loss_list)\n",
        "print(acc_list)\n",
        "\n",
        "plt.figure(figsize=(12, 6))  # 创建一个大图形\n",
        "\n",
        "# 子图1：损失曲线\n",
        "plt.subplot(121)\n",
        "plt.plot(loss_list)\n",
        "plt.title('VGG16-ReTraining Train Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "# 子图2：准确率曲线\n",
        "plt.subplot(122)\n",
        "plt.plot(acc_list, color='green')\n",
        "plt.title('VGG16-ReTraining Test-acc curves')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('acc')\n",
        "\n",
        "# 保存整个图形为一张图片\n",
        "plt.savefig('/content/drive/MyDrive/PytorchTest/ResultImg/VGG16-ReTraining.jpg')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bt7xOW3P5id"
      },
      "source": [
        "**用test集做预测**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0Ucq0eiP5Mz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "import random\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize([224, 224]),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean,\n",
        "                  std)\n",
        "    ])\n",
        "\n",
        "    test_path = r'./data/wheat-leaf-disease/after/test'\n",
        "\n",
        "    # 选择两张图片进行测试\n",
        "    test_image_paths = []\n",
        "    for class_label in class_labels:\n",
        "        class_path = os.path.join(test_path, class_label)\n",
        "        image_files = os.listdir(class_path)\n",
        "        # 从每个子分类中随机选择两张图片\n",
        "        selected_images = random.sample(image_files, 2)\n",
        "        for image_file in selected_images:\n",
        "            test_image_paths.append(os.path.join(class_path, image_file))\n",
        "\n",
        "    label_counts = {label: 0 for label in class_labels}\n",
        "\n",
        "    my_net = models.vgg16()\n",
        "    my_net.classifier[6] = nn.Linear(4096, len(class_labels))  # 调整输出层\n",
        "    my_net.load_state_dict(torch.load('/content/drive/MyDrive/PytorchTest/model/VGG16-wheatleafdiesas_RetrainingModel.pth')) #加载模型测试\n",
        "    my_net = my_net.to(device)\n",
        "    my_net.eval()\n",
        "\n",
        "    for image_path in test_path:\n",
        "        im = Image.open(image_path)\n",
        "        plt.imshow(im)\n",
        "        plt.show()\n",
        "        im = transform(im)\n",
        "        im = torch.unsqueeze(im, dim=0)\n",
        "        im = im.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            label = my_net(im)\n",
        "            pred = label.argmax(dim=1).item()\n",
        "            label_counts[class_labels[pred]] += 1\n",
        "\n",
        "    total_images = len(test_path)\n",
        "    # 计算每个标签的百分比\n",
        "    label_percentages = {label: count / total_images * 100 for label, count in label_counts.items()}\n",
        "\n",
        "    # 绘制柱状图\n",
        "    plt.bar(label_percentages.keys(), label_percentages.values(), color=['blue', 'green', 'red', 'orange'])\n",
        "    plt.xlabel('Labels')\n",
        "    plt.ylabel('Percentage')\n",
        "    plt.title('Percentage of Each Label in Predictions')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5334CkzhKLDz"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
